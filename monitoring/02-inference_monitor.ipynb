{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "576c3dcd-0703-4a04-b788-4bd867f33c73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.39.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a8197bd-39f8-47ec-9cb8-0d0448388ec7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog='dev_bh_datascience'\n",
    "dbName='ds_workshop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5b62982-fc07-4ec4-9965-831f8b57569d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# You must have `USE CATALOG` privileges on the catalog, and you must have `USE SCHEMA` privileges on the schema.\n",
    "# If necessary, change the catalog and schema name here.\n",
    "\n",
    "TABLE_NAME = f\"{catalog}.{dbName}.silver_transaction\"\n",
    "TABLE_NAME_PREDICTIONS = f\"{catalog}.{dbName}.silver_transaction_predictions\"\n",
    "BASELINE_PREDICTIONS = f\"{catalog}.{dbName}.silver_predictions_baseline\"\n",
    "\n",
    "# Define the timestamp column name\n",
    "TIMESTAMP_COL = \"TransactionDate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "088f9fc5-894c-4a0a-9cb0-515b2bd9783f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Predictions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3e8e0b8-445a-431b-b73f-6bc777189fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "(spark.table(TABLE_NAME)\n",
    "   .withColumn(\"Prediction\",  F.least(F.greatest(F.col(\"ProductRating\") + F.randn(), F.lit(0.0)), F.lit(5.0)))\n",
    "   .withColumn(\"ModelVersion\", F.lit(\"1\"))\n",
    "   .withColumn(\"Critical\", F.when(F.col(\"UserRole\") == \"Customer\", F.lit(True)).otherwise(F.lit(False)))\n",
    "   .write\n",
    "   .option(\"overwriteSchema\", \"true\")\n",
    "   .option(\"delta.enableChangeDataFeed\", \"true\")\n",
    "   .mode(\"overwrite\")\n",
    "   .saveAsTable(TABLE_NAME_PREDICTIONS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ed58ee-d7da-481b-bc54-c7fb2ad59130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT ProductRating, Prediction, ModelVersion, Critical from {TABLE_NAME_PREDICTIONS};\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b63880e1-a547-46f7-8b45-17c49dfa7ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create baseline prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "874ce061-862e-4fe9-aee8-5fddf02c9e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "first day we started making predictions as the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1de65773-586f-45d9-8351-52fa4ee22781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW {BASELINE_PREDICTIONS} AS \n",
    "  (SELECT * FROM {TABLE_NAME_PREDICTIONS} \n",
    "  WHERE date({TIMESTAMP_COL}) = (select min(date({TIMESTAMP_COL})) as min_date from {TABLE_NAME_PREDICTIONS})\n",
    "  );\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8fe27e1-1683-43d5-8ed0-e8f61d79d77d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * FROM {BASELINE_PREDICTIONS}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5f79299-2636-42eb-ad1b-a0d0aa8b197a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create an Inference Log Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69b0ec5a-0f96-470d-98b7-2fb36dc8f0fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import MonitorTimeSeries, MonitorInferenceLog, MonitorInferenceLogProblemType\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab3f3a08-ac2e-4633-aa4d-ef54318ca28d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Note that if you create the monitor without a baseline table, you'll see comparisons to prior periods only. With a baseline table, you'll see the metric change relative to your baseline as wel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ded0f4a-6ae1-423c-8bf6-f78e41ca17aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define time windows to aggregate metrics over\n",
    "# Note that granularities must be subsets of \n",
    "# [5 minutes, 30 minutes, 1 hour, 1 day, 1 month, 1 year] \n",
    "# or multiples of [1 week]\n",
    "GRANULARITIES = [\"1 day\", \"1 week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f846cf-f5af-4ad6-86f2-30904d8c7958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a monitor using a Timeseries profile type. After the intial refresh completes, you can view the autogenerated dashboard from the Quality tab of the table in Catalog Explorer. \n",
    "print(f\"Creating monitor for {TABLE_NAME_PREDICTIONS}\")\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "try:\n",
    "  lhm_monitor = w.quality_monitors.create(\n",
    "      table_name=TABLE_NAME_PREDICTIONS, # Always use 3-level namespace\n",
    "      inference_log=MonitorInferenceLog(\n",
    "          problem_type=MonitorInferenceLogProblemType.PROBLEM_TYPE_REGRESSION,\n",
    "          prediction_col=\"Prediction\",\n",
    "          timestamp_col=TIMESTAMP_COL,\n",
    "          granularities=GRANULARITIES,\n",
    "          model_id_col=\"ModelVersion\",\n",
    "          label_col=\"ProductRating\"\n",
    "      ),\n",
    "      baseline_table_name=BASELINE_PREDICTIONS,\n",
    "      assets_dir = os.getcwd(),\n",
    "      output_schema_name=f\"{catalog}.{dbName}\"\n",
    "  )\n",
    "\n",
    "except Exception as lhm_exception:\n",
    "  if \"already exist\" in str(lhm_exception):\n",
    "      print(f\"Monitor for {TABLE_NAME_PREDICTIONS} already exists, retrieving monitor info:\")\n",
    "      lhm_monitor = w.quality_monitors.get(table_name=f\"{TABLE_NAME_PREDICTIONS}\")\n",
    "  else:\n",
    "      raise lhm_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd3f761-5fe3-484c-b6d2-bf376823c162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from databricks.sdk.service.catalog import MonitorInfoStatus, MonitorRefreshInfoState\n",
    "\n",
    "\n",
    "# Wait for monitor to be created\n",
    "lhm_monitor = w.quality_monitors.get(table_name=f\"{TABLE_NAME_PREDICTIONS}\")\n",
    "while lhm_monitor.status == MonitorInfoStatus.MONITOR_STATUS_PENDING:\n",
    "  lhm_monitor = w.quality_monitors.get(table_name=f\"{TABLE_NAME_PREDICTIONS}\")\n",
    "  time.sleep(10)\n",
    "\n",
    "assert lhm_monitor.status == MonitorInfoStatus.MONITOR_STATUS_ACTIVE, \"Error creating monitor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eabde27-56a2-4055-93e4-4e7a17d1ec7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "refreshes = w.quality_monitors.list_refreshes(table_name=f\"{TABLE_NAME_PREDICTIONS}\").refreshes\n",
    "assert(len(refreshes) > 0)\n",
    "\n",
    "run_info = refreshes[0]\n",
    "while run_info.state in (MonitorRefreshInfoState.PENDING, MonitorRefreshInfoState.RUNNING):\n",
    "  run_info = w.quality_monitors.get_refresh(table_name=f\"{TABLE_NAME_PREDICTIONS}\", refresh_id=run_info.refresh_id)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert run_info.state == MonitorRefreshInfoState.SUCCESS, \"Monitor refresh failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018b6566-d574-4269-89b8-46f288886adb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display profile metrics table\n",
    "profile_table = lhm_monitor.profile_metrics_table_name\n",
    "display(spark.sql(f\"SELECT * FROM {profile_table}\"))\n",
    "\n",
    "# Display the drift metrics table\n",
    "drift_table = lhm_monitor.drift_metrics_table_name\n",
    "display(spark.sql(f\"SELECT * FROM {drift_table}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e970cfec-a547-405f-905a-ac5ad345568d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profile_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a9dda0-9829-4139-9ae6-49cc86f611e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "drift_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb02ee43-6565-460c-8208-490d44428f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT window, mean_squared_error, r2_score from {profile_table} where mean_squared_error is not null\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e998b387-ad26-46e6-b5ba-b1a975d3d7fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * from {drift_table} where drift_type = 'BASELINE';\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae0e4557-de6d-4902-869a-90bb96fb1e77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Add Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6983024-197c-48fd-afa3-dc05c25246b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We'll create two aggregate metrics and then one derived metric that will contain the weighted mean squared error. We're using the Critical column that we added when we created the predictions table to add extra weight to some of the predictions. Remember, we labelled a row as critical if it was for a customer instead of an admin.\n",
    "\n",
    "The two aggregate metrics will be the sum of weights and the weighted sum of squared prediction errors. Then we'll dive the weighted sum by the sum of the weights to get the weighted mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2955b4d4-77bc-4055-92b1-f25b9681a142",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sum of the weights"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.catalog import MonitorMetric, MonitorMetricType\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "\n",
    "weights_sum = MonitorMetric(\n",
    "    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,\n",
    "    name=\"weights_sum\",\n",
    "    input_columns=[\":table\"],\n",
    "    definition=\"\"\"sum(CASE\n",
    "      WHEN {{prediction_col}} = {{label_col}} THEN 0\n",
    "      WHEN {{prediction_col}} != {{label_col}} AND Critical=TRUE THEN 2\n",
    "      ELSE 1 END)\"\"\",\n",
    "    output_data_type=T.StructField(\"weights_sum\", T.DoubleType()).json(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9833ab2f-4f74-4eab-ae99-14e5b121540e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Weighted sum of the squared errors"
    }
   },
   "outputs": [],
   "source": [
    "weighted_se = MonitorMetric(\n",
    "    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,\n",
    "    name=\"weighted_se\",\n",
    "    input_columns=[\":table\"],\n",
    "    definition=\"\"\"sum(CASE\n",
    "      WHEN {{prediction_col}} = {{label_col}} THEN 0\n",
    "      WHEN {{prediction_col}} != {{label_col}} AND Critical=TRUE THEN 2 * POWER({{prediction_col}} - {{label_col}}, 2)\n",
    "      ELSE POWER({{prediction_col}} - {{label_col}}, 2) END)\"\"\",\n",
    "    output_data_type=T.StructField(\"weighted_se\", T.DoubleType()).json(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f56cac-72a7-4955-b86b-3db94a7a1388",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "weighted mean squared error"
    }
   },
   "outputs": [],
   "source": [
    "weighted_mse = MonitorMetric(\n",
    "    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,\n",
    "    name=\"weighted_mse\",\n",
    "    input_columns=[\":table\"],\n",
    "    definition=\"\"\"weighted_se / weights_sum\"\"\",\n",
    "    output_data_type=T.StructField(\"weighted_mse\", T.DoubleType()).json(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1242316-4b1c-49cd-a251-d6e37a3fe300",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "add in a drift metric that compares r2 scores across periods"
    }
   },
   "outputs": [],
   "source": [
    "r2_score_delta = MonitorMetric(\n",
    "    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DRIFT,\n",
    "    name=\"r2_score_delta\",\n",
    "    input_columns=[\":table\"],\n",
    "    definition=\"{{current_df}}.r2_score - {{base_df}}.r2_score\",\n",
    "    output_data_type=T.StructField(\"r2_score_delta\", T.DoubleType()).json(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85d0de6f-a46e-4522-aa81-3f51f4d0db81",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update the monitor and add in the custom metrics"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  lhm_monitor = w.quality_monitors.update(\n",
    "      table_name=TABLE_NAME_PREDICTIONS, # Always use 3-level namespace\n",
    "      inference_log=MonitorInferenceLog(\n",
    "          problem_type=MonitorInferenceLogProblemType.PROBLEM_TYPE_REGRESSION,\n",
    "          prediction_col=\"Prediction\",\n",
    "          timestamp_col=TIMESTAMP_COL,\n",
    "          granularities=GRANULARITIES,\n",
    "          model_id_col=\"ModelVersion\",\n",
    "          label_col=\"ProductRating\", # optional\n",
    "      ),\n",
    "      custom_metrics=[weights_sum, weighted_se, weighted_mse, r2_score_delta],\n",
    "      baseline_table_name=BASELINE_PREDICTIONS,\n",
    "      output_schema_name=f\"{catalog}.{dbName}\"\n",
    "  )\n",
    "\n",
    "except Exception as lhm_exception:\n",
    "  print(lhm_exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aed2f8c5-4ff4-42aa-a234-0282a295029c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "refresh after an update to see the new fields"
    }
   },
   "outputs": [],
   "source": [
    "w = WorkspaceClient()\n",
    "run_info = w.quality_monitors.run_refresh(TABLE_NAME_PREDICTIONS)\n",
    "\n",
    "while run_info.state in (MonitorRefreshInfoState.PENDING, MonitorRefreshInfoState.RUNNING):\n",
    "  run_info = w.quality_monitors.get_refresh(table_name=f\"{TABLE_NAME_PREDICTIONS}\", refresh_id=run_info.refresh_id)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert run_info.state == MonitorRefreshInfoState.SUCCESS, \"Monitor refresh failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8731199a-b90e-4cfe-8940-a34bcc820be8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56ce5ab3-e1e2-4e19-8d49-67976c1dcf26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * from {profile_table} limit 10;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a2d074-94be-48ed-9067-96053a921204",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "profile table"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT window, mean_squared_error, weights_sum, weighted_mse from {profile_table} where weights_sum is not null;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38843688-f752-4b61-b293-6397cbee9aec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT window, r2_score_delta, drift_type from {drift_table} limit 10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ded2340-df8c-47b0-9d17-43dc21fceac1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "drift table"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT window, r2_score_delta, drift_type from {drift_table} where drift_type = 'BASELINE';\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb52f5ce-e3d3-41ac-bf67-2ae7a9a6ae9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following codes will delete the monitor under the quality of the delta table. But the profile table and drift table in unity catalog are note deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f202ee3-9ce0-4ab4-9f84-584a85532acd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the following line of code to clean up the monitor (if you wish to run the quickstart on this table again).\n",
    "w.quality_monitors.delete(TABLE_NAME_PREDICTIONS)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-inference_monitor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
