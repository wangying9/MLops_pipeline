{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b7c70c9-5244-4e68-be33-c2b7bfbf0774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.39.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0c9fa2-104d-4d63-8b7d-883dda158f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog='dev_bh_datascience'\n",
    "dbName='ds_workshop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b5f0f1e-5291-48f0-8463-210a768b7a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"use catalog dev_bh_datascience\")\n",
    "spark.sql(\"use database ds_workshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a9de18-dfe8-43be-8bf5-861e272b76ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- To setup monitoring, load in the silver_transaction dataset\n",
    "SELECT * from silver_transaction limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0164a00b-bfe0-4819-9668-9f8488d48c8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c345d6d-c4e8-4cfe-b08b-1d298c58c50f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import MonitorTimeSeries\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c871a7-025c-477f-ad9f-63d23afcc3ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define time windows to aggregate metrics over\n",
    "GRANULARITIES = [\"1 day\"]                       \n",
    "\n",
    "# Optionally define expressions to slice data with\n",
    "SLICING_EXPRS = [\"Category='Toys'\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da067c44-b222-4ca9-904c-bd923a6341cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# You must have `USE CATALOG` privileges on the catalog, and you must have `USE SCHEMA` privileges on the schema.\n",
    "# If necessary, change the catalog and schema name here.\n",
    "TABLE_NAME = f\"{catalog}.{dbName}.silver_transaction\"\n",
    "\n",
    "# Define the timestamp column name\n",
    "TIMESTAMP_COL = \"TransactionDate\"\n",
    "\n",
    "# Enable Change Data Feed (CDF) to incrementally process changes to the table and make execution more efficient \n",
    "display(spark.sql(f\"ALTER TABLE {TABLE_NAME} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a22cc76b-f870-4c5d-8ba1-095976c2d9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a monitor using a Timeseries profile type. After the intial refresh completes, you can view the autogenerated dashboard from the Quality tab of the table in Catalog Explorer. \n",
    "print(f\"Creating monitor for {TABLE_NAME}\")\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "try:\n",
    "  lhm_monitor = w.quality_monitors.create(\n",
    "    table_name=TABLE_NAME, # Always use 3-level namespace\n",
    "    time_series = MonitorTimeSeries(\n",
    "      timestamp_col=TIMESTAMP_COL,\n",
    "      granularities=GRANULARITIES\n",
    "    ),\n",
    "    assets_dir = os.getcwd(),\n",
    "    output_schema_name=f\"{catalog}.{dbName}\"\n",
    "  )\n",
    "  \n",
    "except Exception as lhm_exception:\n",
    "  if \"already exist\" in str(lhm_exception):\n",
    "    print(f\"Monitor for {TABLE_NAME} already exists, retrieving monitor info:\")\n",
    "    lhm_monitor = w.quality_monitors.get(table_name=f\"{TABLE_NAME}\")\n",
    "\n",
    "  else:\n",
    "    raise lhm_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "594e1a72-4552-4943-ad86-91a334e21b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from databricks.sdk.service.catalog import MonitorInfoStatus, MonitorRefreshInfoState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fd20be6-ac6a-465b-aa34-931c87faf73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wait for monitor to be created\n",
    "lhm_monitor = w.quality_monitors.get(table_name=f\"{TABLE_NAME}\")\n",
    "while lhm_monitor.status == MonitorInfoStatus.MONITOR_STATUS_PENDING:\n",
    "  lhm_monitor = w.quality_monitors.get(table_name=f\"{TABLE_NAME}\")\n",
    "  time.sleep(10)\n",
    "\n",
    "assert lhm_monitor.status == MonitorInfoStatus.MONITOR_STATUS_ACTIVE, \"Error creating monitor\"\n",
    "\n",
    "refreshes = w.quality_monitors.list_refreshes(table_name=f\"{TABLE_NAME}\").refreshes\n",
    "assert(len(refreshes) > 0)\n",
    "\n",
    "run_info = refreshes[0]\n",
    "while run_info.state in (MonitorRefreshInfoState.PENDING, MonitorRefreshInfoState.RUNNING):\n",
    "  run_info = w.quality_monitors.get_refresh(table_name=f\"{TABLE_NAME}\", refresh_id=run_info.refresh_id)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert run_info.state == MonitorRefreshInfoState.SUCCESS, \"Monitor refresh failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fad4958e-12ec-49c4-abb3-e4ffa2fdb1c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Orientation to the profile metrics table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f574ed1-513d-4131-ae50-b403236c82a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The profile metrics table has the suffix _profile_metrics. For a list of statistics that are shown in the table, see the documentation (AWS|Azure).\n",
    "\n",
    "For every column in the primary table, the profile table shows summary statistics for the baseline table and for the primary table. The column log_type shows INPUT to indicate statistics for the primary table, and BASELINE to indicate statistics for the baseline table. The column from the primary table is identified in the column column_name.\n",
    "For TimeSeries type analysis, the granularity column shows the granularity corresponding to the row. For baseline table statistics, the granularity column shows null.\n",
    "The table shows statistics for each value of each slice key in each time window, and for the table as whole. Statistics for the table as a whole are indicated by slice_key = slice_value = null.\n",
    "In the primary table, the window column shows the time window corresponding to that row. For baseline table statistics, the window column shows null.\n",
    "Some statistics are calculated based on the table as a whole, not on a single column. In the column column_name, these statistics are identified by :table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd92af9b-21aa-41c4-843c-ddaccb6b953d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display profile metrics table\n",
    "profile_table = lhm_monitor.profile_metrics_table_name  \n",
    "display(spark.sql(f\"SELECT * FROM {profile_table}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c96ded28-fe94-40b9-a627-9ecd89678662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profile_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7ab0e94-67d5-43c9-99b6-4ebd02ffc410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Orientation to the drift metrics table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dc76c42-4b2d-4b95-81cb-000819c1a1e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The drift metrics table has the suffix _drift_metrics. For a list of statistics that are shown in the table, see the documentation (AWS | Azure).\n",
    "\n",
    "For every column in the primary table, the drift table shows a set of metrics that compare the current values in the table to the values at the time of the previous analysis run and to the baseline table. The column drift_type shows BASELINE to indicate drift relative to the baseline table, and CONSECUTIVE to indicate drift relative to a previous time window. As in the profile table, the column from the primary table is identified in the column column_name.\n",
    "For TimeSeries type analysis, the granularity column shows the granularity corresponding to that row.\n",
    "The table shows statistics for each value of each slice key in each time window, and for the table as whole. Statistics for the table as a whole are indicated by slice_key = slice_value = null.\n",
    "The window column shows the the time window corresponding to that row. The window_cmp column shows the comparison window. If the comparison is to the baseline table, window_cmp is null.\n",
    "Some statistics are calculated based on the table as a whole, not on a single column. In the column column_name, these statistics are identified by :table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dde1746-1d56-42da-8988-b9ae701c9f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the drift metrics table\n",
    "drift_table = lhm_monitor.drift_metrics_table_name  \n",
    "display(spark.sql(f\"SELECT * FROM {drift_table}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "289c2e6c-1799-4b79-874b-405063c18272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "drift_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73bf118f-c209-42fd-a846-fd276774cc25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### One col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b4a2c7e-7d04-4063-b2b2-0b868a79edea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * FROM {profile_table} where column_name = 'TotalPurchaseAmount'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4240ec4-e95a-42c8-b2c9-89e4fa981b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * FROM {drift_table} where column_name = 'TotalPurchaseAmount'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d9af7a0-5ba8-4b25-ad7e-487a0eb8b9d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View the Autogenerated Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "726e5fc3-93e8-4081-b352-87e122536701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "After the intial refresh completes, you can view the autogenerated dashboard from the Quality tab of the silver_transactions table in Catalog Explorer. The dashboard visualizes metrics in the following sections:\n",
    "\n",
    "Data Volume: Check if transaction volume is expected or if there's been changes with seasonality\n",
    "Data Integrity: Identify the columns with a high % of nulls or zeros and view their distribution over time\n",
    "Numerical Distribution Change: Identify numerical anomalies and view the Range of values over time\n",
    "Categorical Distribution Change: Identify categorical anomalies like PreferredPaymentMethod and view the distribution of values time\n",
    "Profiling: Explore the numerical and categorical data profile over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b92a72a7-a950-4b19-b169-baf706deb069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Delete tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05732d56-83e8-4b25-9921-8363124f08a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the following line of code to clean up the monitor (if you wish to run the quickstart on this table again).\n",
    "w.quality_monitors.delete(TABLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 526039306867389,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01-Timeseries_Monitor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
