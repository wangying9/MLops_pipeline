{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b17a5930-39fa-46eb-b5ce-6c42da445c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "https://notebooks.databricks.com/demos/lakehouse-monitoring/index.html#\n",
    "\n",
    "https://www.databricks.com/resources/demos/tutorials/data-warehouse-and-bi/monitor-your-data-quality-with-lakehouse-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92fbd8b9-f178-4b7d-a70a-8d8b87074dd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "460667b9-d7bc-4881-b5d6-2552dd0c3df5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog='dev_bh_datascience'\n",
    "dbName='ds_workshop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16ee405-5b49-4a50-ba38-d1312aa81852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"use catalog dev_bh_datascience\")\n",
    "spark.sql(\"use database ds_workshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5bd8e44-c7b0-4bf2-8f85-8546d530a142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_exists = spark.catalog.tableExists('gold_user_purchase') and spark.catalog.tableExists('bronze_product') and spark.catalog.tableExists('bronze_user') and spark.catalog.tableExists('bronze_transaction') and spark.catalog.tableExists('gold_payment_method') \n",
    "\n",
    "if data_exists:\n",
    "  print(f'data alread existing in {catalog}.{dbName}. Please drop the schema to re-create them from scratch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "273a33e0-de35-41c9-bc5a-762d747a5e41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate user table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c82f874-bfc4-4dfc-a286-5f0b5203d110",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    import pandas as pd\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "    from faker import Faker\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType, BooleanType, ArrayType, IntegerType, TimestampType, DoubleType\n",
    "\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # Function to generate user data\n",
    "    def generate_user_data(num_rows=10000):\n",
    "        user_data = []\n",
    "        \n",
    "        for _ in range(num_rows):\n",
    "            user = {\n",
    "                \"UserID\": fake.uuid4(),\n",
    "                \"Username\": fake.user_name(),\n",
    "                \"Email\": fake.email(),\n",
    "                \"PasswordHash\": fake.sha256(),\n",
    "                \"FullName\": fake.name(),\n",
    "                \"DateOfBirth\": fake.date_of_birth(minimum_age=18, maximum_age=90),\n",
    "                \"Gender\": random.choice([\"Male\", \"Female\", \"Other\"]),\n",
    "                \"PhoneNumber\": fake.phone_number(),\n",
    "                \"Address\": fake.address(),\n",
    "                \"City\": fake.city(),\n",
    "                \"State\": fake.state(),\n",
    "                \"Country\": fake.country(),\n",
    "                \"PostalCode\": fake.postcode(),\n",
    "                \"RegistrationDate\": fake.date_this_decade(),\n",
    "                \"LastLoginDate\": fake.date_time_between(start_date=\"-1y\", end_date=\"now\"),\n",
    "                \"AccountStatus\": random.choice([\"Active\", \"Suspended\", \"Inactive\"]),\n",
    "                \"UserRole\": random.choice([\"Customer\", \"Admin\"]),\n",
    "                \"PreferredPaymentMethod\": random.choice([\"Credit Card\", \"Debit Card\", \"PayPal\", \"Bank Transfer\"]),\n",
    "                \"TotalPurchaseAmount\": round(random.uniform(0, 10000), 2),\n",
    "                \"NewsletterSubscription\": random.choice([True, False]),\n",
    "                \"Wishlist\": [fake.uuid4() for _ in range(random.randint(0, 10))],\n",
    "                \"CartItems\": [fake.uuid4() for _ in range(random.randint(0, 5))]\n",
    "            }\n",
    "            user_data.append(user)\n",
    "        \n",
    "        return pd.DataFrame(user_data)\n",
    "\n",
    "    # Generate the user data\n",
    "    user_pdf = generate_user_data(10000)\n",
    "\n",
    "    # Convert the Pandas DataFrame to a PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"UserID\", StringType(), False),\n",
    "        StructField(\"Username\", StringType(), False),\n",
    "        StructField(\"Email\", StringType(), False),\n",
    "        StructField(\"PasswordHash\", StringType(), False),\n",
    "        StructField(\"FullName\", StringType(), False),\n",
    "        StructField(\"DateOfBirth\", DateType(), False),\n",
    "        StructField(\"Gender\", StringType(), False),\n",
    "        StructField(\"PhoneNumber\", StringType(), False),\n",
    "        StructField(\"Address\", StringType(), False),\n",
    "        StructField(\"City\", StringType(), False),\n",
    "        StructField(\"State\", StringType(), False),\n",
    "        StructField(\"Country\", StringType(), False),\n",
    "        StructField(\"PostalCode\", StringType(), False),\n",
    "        StructField(\"RegistrationDate\", DateType(), False),\n",
    "        StructField(\"LastLoginDate\", DateType(), False),\n",
    "        StructField(\"AccountStatus\", StringType(), False),\n",
    "        StructField(\"UserRole\", StringType(), False),\n",
    "        StructField(\"PreferredPaymentMethod\", StringType(), False),\n",
    "        StructField(\"TotalPurchaseAmount\", FloatType(), False),\n",
    "        StructField(\"NewsletterSubscription\", BooleanType(), False),\n",
    "        StructField(\"Wishlist\", ArrayType(StringType()), False),\n",
    "        StructField(\"CartItems\", ArrayType(StringType()), False)\n",
    "    ])\n",
    "\n",
    "    # Create Spark DataFrame and Write to Delta\n",
    "    user_df = spark.createDataFrame(user_pdf, schema)\n",
    "\n",
    "    # Write the Spark DataFrame to Delta format\n",
    "    user_df.write.mode('overwrite').saveAsTable('bronze_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0988faa-4f61-484c-8f71-ec1409db9232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Product table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd2e60eb-e00e-47ee-b7ce-15a0b873c3d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    import random\n",
    "\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # Expanded list of realistic product names related to categories\n",
    "    product_names = {\n",
    "        \"Electronics\": [\n",
    "            \"Smartphone\", \"Laptop\", \"Tablet\", \"Desktop Computer\", \"Camera\", \"Headphones\", \"Speakers\", \"Smartwatch\",\n",
    "            \"Fitness Tracker\", \"Bluetooth Earbuds\", \"Gaming Console\", \"Television\"\n",
    "        ],\n",
    "        \"Clothing\": [\n",
    "            \"Running Shoes\", \"Hiking Boots\", \"Sneakers\", \"Sandals\", \"Slippers\", \"Formal Shoes\", \"Wrist Watch\",\n",
    "            \"Sunglasses\", \"Handbag\", \"Backpack\", \"T-Shirt\", \"Sweater\", \"Jacket\", \"Jeans\", \"Dress\", \"Skirt\", \"Shorts\",\n",
    "            \"Swimwear\", \"Hat\", \"Scarf\"\n",
    "        ],\n",
    "        \"Home & Kitchen\": [\n",
    "            \"Vacuum Cleaner\", \"Blender\", \"Microwave Oven\", \"Refrigerator\", \"Air Conditioner\", \"Heater\", \"Fan\",\n",
    "            \"Electric Kettle\", \"Coffee Maker\", \"Toaster\", \"Cookware Set\", \"Knife Set\", \"Cutting Board\"\n",
    "        ],\n",
    "        \"Books\": [\n",
    "            \"Cookbook\", \"Novel\", \"Textbook\", \"Journal\", \"Notebook\", \"Children's Book\"\n",
    "        ],\n",
    "        \"Toys\": [\n",
    "            \"Puzzle\", \"Board Game\", \"Action Figure\", \"Doll\", \"Toy Car\", \"Building Blocks\"\n",
    "        ],\n",
    "        \"Sports\": [\n",
    "            \"Bicycle\", \"Treadmill\", \"Dumbbells\", \"Yoga Mat\", \"Protein Powder\"\n",
    "        ],\n",
    "        \"Health & Beauty\": [\n",
    "            \"Skincare Set\", \"Shampoo\", \"Conditioner\", \"Hair Dryer\", \"Electric Toothbrush\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    subcategories = {\n",
    "        \"Electronics\": [\"Smartphones\", \"Laptops\", \"Cameras\", \"Headphones\", \"Speakers\"],\n",
    "        \"Clothing\": [\"Men\", \"Women\", \"Kids\", \"Accessories\", \"Footwear\"],\n",
    "        \"Home & Kitchen\": [\"Appliances\", \"Cookware\", \"Furniture\", \"Decor\", \"Bedding\"],\n",
    "        \"Books\": [\"Fiction\", \"Non-Fiction\", \"Children's Books\", \"Educational\", \"Mystery\"],\n",
    "        \"Toys\": [\"Educational Toys\", \"Action Figures\", \"Board Games\", \"Dolls\", \"Puzzles\"],\n",
    "        \"Sports\": [\"Fitness Equipment\", \"Outdoor Gear\", \"Team Sports\", \"Individual Sports\", \"Sportswear\"],\n",
    "        \"Health & Beauty\": [\"Skincare\", \"Makeup\", \"Supplements\", \"Haircare\", \"Personal Care\"]\n",
    "    }\n",
    "\n",
    "    # Expanded list of realistic brand names\n",
    "    brands = [\n",
    "        \"BrandA\", \"BrandB\", \"BrandC\", \"BrandD\", \"BrandE\", \"BrandF\", \"BrandG\", \"BrandH\", \"BrandI\", \"BrandJ\",\n",
    "        \"BrandK\", \"BrandL\", \"BrandM\", \"BrandN\", \"BrandO\", \"BrandP\", \"BrandQ\", \"BrandR\", \"BrandS\", \"BrandT\",\n",
    "        \"BrandU\", \"BrandV\", \"BrandW\", \"BrandX\", \"BrandY\", \"BrandZ\", \"BrandAA\", \"BrandBB\", \"BrandCC\", \"BrandDD\",\n",
    "        \"BrandEE\", \"BrandFF\", \"BrandGG\", \"BrandHH\", \"BrandII\", \"BrandJJ\", \"BrandKK\", \"BrandLL\", \"BrandMM\", \"BrandNN\",\n",
    "        \"BrandOO\", \"BrandPP\", \"BrandQQ\", \"BrandRR\", \"BrandSS\", \"BrandTT\", \"BrandUU\", \"BrandVV\", \"BrandWW\", \"BrandXX\"\n",
    "    ]\n",
    "\n",
    "    # Category-specific descriptions\n",
    "    descriptions = {\n",
    "        \"Electronics\": [\n",
    "            \"Latest technology with cutting-edge features.\",\n",
    "            \"High performance and sleek design.\",\n",
    "            \"Ideal for tech enthusiasts and professionals.\",\n",
    "            \"Reliable and durable with excellent battery life.\",\n",
    "            \"Compact and lightweight for easy portability.\"\n",
    "        ],\n",
    "        \"Clothing\": [\n",
    "            \"Comfortable and stylish for any occasion.\",\n",
    "            \"Made from high-quality materials for a perfect fit.\",\n",
    "            \"Trendy design that stands out.\",\n",
    "            \"Versatile and easy to pair with different outfits.\",\n",
    "            \"Durable fabric for long-lasting wear.\"\n",
    "        ],\n",
    "        \"Home & Kitchen\": [\n",
    "            \"Essential appliance for modern homes.\",\n",
    "            \"Stylish design to complement your kitchen.\",\n",
    "            \"Energy-efficient and easy to use.\",\n",
    "            \"High performance for all your cooking needs.\",\n",
    "            \"Compact design saves space.\"\n",
    "        ],\n",
    "        \"Books\": [\n",
    "            \"Engaging story that captivates readers.\",\n",
    "            \"Informative and educational content.\",\n",
    "            \"Perfect for readers of all ages.\",\n",
    "            \"Beautifully illustrated with vibrant colors.\",\n",
    "            \"Thought-provoking and inspiring.\"\n",
    "        ],\n",
    "        \"Toys\": [\n",
    "            \"Fun and educational for children.\",\n",
    "            \"Safe and durable materials.\",\n",
    "            \"Encourages creativity and imagination.\",\n",
    "            \"Perfect gift for kids of all ages.\",\n",
    "            \"Bright and colorful design.\"\n",
    "        ],\n",
    "        \"Sports\": [\n",
    "            \"High-performance gear for athletes.\",\n",
    "            \"Durable and lightweight materials.\",\n",
    "            \"Designed for comfort and efficiency.\",\n",
    "            \"Ideal for both beginners and professionals.\",\n",
    "            \"Enhances your performance in sports.\"\n",
    "        ],\n",
    "        \"Health & Beauty\": [\n",
    "            \"Nourishes and revitalizes your skin.\",\n",
    "            \"High-quality ingredients for best results.\",\n",
    "            \"Suitable for all skin types.\",\n",
    "            \"Enhances your natural beauty.\",\n",
    "            \"Gentle and effective formula.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Function to generate product data\n",
    "    def generate_product_data(num_rows=10000):\n",
    "        product_data = []\n",
    "        \n",
    "        for _ in range(num_rows):\n",
    "            category = random.choice(list(subcategories.keys()))\n",
    "            product = {\n",
    "                \"ProductID\": fake.uuid4(),\n",
    "                \"ProductName\": random.choice(product_names[category]),\n",
    "                \"Category\": category,\n",
    "                \"SubCategory\": random.choice(subcategories[category]),\n",
    "                \"Brand\": random.choice(brands),\n",
    "                \"Description\": random.choice(descriptions[category]),\n",
    "                \"Price\": round(random.uniform(5, 2000), 2),\n",
    "                \"Discount\": round(random.uniform(0, 0.5), 2),  # Discount as a fraction\n",
    "                \"StockQuantity\": random.randint(0, 1000),\n",
    "                \"SKU\": fake.bothify(text='???-########'),\n",
    "                \"ProductImageURL\": fake.image_url(),\n",
    "                \"ProductRating\": round(random.uniform(1, 5), 1),\n",
    "                \"NumberOfReviews\": random.randint(0, 5000),\n",
    "                \"SupplierID\": fake.uuid4(),\n",
    "                \"DateAdded\": fake.date_this_decade(),\n",
    "                \"Dimensions\": f\"{random.uniform(1, 100):.2f} x {random.uniform(1, 100):.2f} x {random.uniform(1, 100):.2f}\",\n",
    "                \"Weight\": round(random.uniform(0.1, 50), 2),\n",
    "                \"Color\": fake.color_name(),\n",
    "                \"Material\": random.choice([\"Plastic\", \"Metal\", \"Wood\", \"Glass\", \"Fabric\"]),\n",
    "                \"WarrantyPeriod\": f\"{random.randint(1, 24)} months\",\n",
    "                \"ReturnPolicy\": random.choice([\"30 days\", \"60 days\", \"No returns\"]),\n",
    "                \"ShippingCost\": round(random.uniform(0, 50), 2),\n",
    "                \"ProductTags\": [fake.word() for _ in range(random.randint(1, 5))]\n",
    "            }\n",
    "            product_data.append(product)\n",
    "        \n",
    "        return pd.DataFrame(product_data)\n",
    "\n",
    "    # Generate the product data\n",
    "    product_pdf = generate_product_data(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9284c462-16e1-47de-b4ef-2725966701bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0292e04d-1c4b-4fee-9e35-d2ee0321a054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Convert the Pandas DataFrame to a PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"ProductID\", StringType(), False),\n",
    "        StructField(\"ProductName\", StringType(), False),\n",
    "        StructField(\"Category\", StringType(), False),\n",
    "        StructField(\"SubCategory\", StringType(), False),\n",
    "        StructField(\"Brand\", StringType(), False),\n",
    "        StructField(\"Description\", StringType(), False),\n",
    "        StructField(\"Price\", FloatType(), False),\n",
    "        StructField(\"Discount\", FloatType(), False),\n",
    "        StructField(\"StockQuantity\", IntegerType(), False),\n",
    "        StructField(\"SKU\", StringType(), False),\n",
    "        StructField(\"ProductImageURL\", StringType(), False),\n",
    "        StructField(\"ProductRating\", FloatType(), False),\n",
    "        StructField(\"NumberOfReviews\", IntegerType(), False),\n",
    "        StructField(\"SupplierID\", StringType(), False),\n",
    "        StructField(\"DateAdded\", DateType(), False),\n",
    "        StructField(\"Dimensions\", StringType(), False),\n",
    "        StructField(\"Weight\", FloatType(), False),\n",
    "        StructField(\"Color\", StringType(), False),\n",
    "        StructField(\"Material\", StringType(), False),\n",
    "        StructField(\"WarrantyPeriod\", StringType(), False),\n",
    "        StructField(\"ReturnPolicy\", StringType(), False),\n",
    "        StructField(\"ShippingCost\", FloatType(), False),\n",
    "        StructField(\"ProductTags\", ArrayType(StringType()), False)\n",
    "    ])\n",
    "\n",
    "    # Create Spark DataFrame & Write to Delta\n",
    "    product_df = spark.createDataFrame(product_pdf, schema)\n",
    "    product_df.write.mode('overwrite').saveAsTable('bronze_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2159e269-2a37-4ddd-992a-52e79d8babf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # Function to generate transaction data\n",
    "    def generate_transaction_data(user_pdf_, product_pdf_, start_date_, end_date_, campaigns={}):\n",
    "        transaction_data = []\n",
    "        \n",
    "        # Convert date strings to datetime objects\n",
    "        start_date = datetime.strptime(start_date_, \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(end_date_, \"%Y-%m-%d\")\n",
    "        \n",
    "        # Define seasonality factors\n",
    "        seasonality_factors = {\n",
    "            \"winter\": 1.6,\n",
    "            \"spring\": 1.1,\n",
    "            \"summer\": 1.2,\n",
    "            \"autumn\": 1.4\n",
    "        }\n",
    "        \n",
    "        # Iterate over each date in the range\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            # Determine seasonality factor based on month\n",
    "            month = current_date.month\n",
    "            if month in [12, 1]:\n",
    "                seasonality_factor = seasonality_factors[\"winter\"]\n",
    "            elif month in [2, 3, 4, 5]:\n",
    "                seasonality_factor = seasonality_factors[\"spring\"]\n",
    "            elif month in [6, 7, 8]:\n",
    "                seasonality_factor = seasonality_factors[\"summer\"]\n",
    "            else:\n",
    "                seasonality_factor = seasonality_factors[\"autumn\"]\n",
    "            \n",
    "            # Determine weekday/weekend factor\n",
    "            if current_date.weekday() < 5:  # Weekday\n",
    "                day_factor = 1.0\n",
    "            else:  # Weekend\n",
    "                day_factor = 1.3\n",
    "            \n",
    "            # Determine marketing campaign factor\n",
    "            campaign_factor = campaigns.get(current_date.strftime(\"%Y-%m-%d\"), 1.0)\n",
    "            \n",
    "            # Calculate the base number of transactions for the day\n",
    "            base_transactions = int(100 * day_factor * seasonality_factor * campaign_factor)\n",
    "            \n",
    "            # Apply a random multiplier to introduce variability\n",
    "            random_multiplier = random.uniform(0.9, 1.1)  # Adjust the range for desired variability\n",
    "            daily_transactions = int(base_transactions * random_multiplier)\n",
    "            \n",
    "            # Generate transactions for the day\n",
    "            for _ in range(daily_transactions):\n",
    "                user = user_pdf_.sample(1).iloc[0]\n",
    "                product = product_pdf_.sample(1).iloc[0]\n",
    "                quantity = random.randint(1, 5)\n",
    "                transaction = {\n",
    "                    \"TransactionID\": fake.uuid4(),\n",
    "                    \"UserID\": user[\"UserID\"],\n",
    "                    \"ProductID\": product[\"ProductID\"],\n",
    "                    \"TransactionDate\": fake.date_time_between(start_date=current_date, end_date=current_date + timedelta(days=1)),\n",
    "                    \"Quantity\": quantity,\n",
    "                    \"UnitPrice\": product[\"Price\"],\n",
    "                    \"TotalPrice\": round(product[\"Price\"] * quantity, 2),\n",
    "                    \"PaymentMethod\": random.choice([\"Credit Card\", \"Debit Card\", \"PayPal\", \"Bank Transfer\"]),\n",
    "                    \"ShippingAddress\": user[\"Address\"],\n",
    "                    \"LoyaltyPointsEarned\": int(round(product[\"Price\"] * quantity * 0.1)),  # Example: 10% of the total price in loyalty points\n",
    "                    \"GiftWrap\": random.choice([\"yes\", \"no\"]),\n",
    "                    \"SpecialInstructions\": fake.sentence() if random.choice([True, False]) else \"\"\n",
    "                }\n",
    "                transaction_data.append(transaction)\n",
    "            \n",
    "            # Move to the next day\n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        return pd.DataFrame(transaction_data)\n",
    "\n",
    "    # Generate the transaction data\n",
    "    # Set the current date\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Calculate the start date (30 days from now)\n",
    "    start_date = (current_date - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Set the end date to today\n",
    "    end_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Define the campaigns with the last campaign date being 8 days before today\n",
    "    campaigns = {\n",
    "        # \"2023-07-15\": 2.0 ,  # Example campaign day with doubled sales\n",
    "        # \"2023-11-23\": 1.5 ,  # Another example campaign day with 50% higher sales\n",
    "        # \"2024-03-10\": 2.0 , # Example campaign day with doubled sales\n",
    "        (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\"): 2.0  # Last campaign date is today - 1 days\n",
    "    }\n",
    "\n",
    "    # Generate the transaction data\n",
    "    transaction_pdf = generate_transaction_data(user_pdf, product_pdf, start_date, end_date, campaigns)\n",
    "\n",
    "    # Convert the Pandas DataFrame to a PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"TransactionID\", StringType(), False),\n",
    "        StructField(\"UserID\", StringType(), False),\n",
    "        StructField(\"ProductID\", StringType(), False),\n",
    "        StructField(\"TransactionDate\", TimestampType(), False),\n",
    "        StructField(\"Quantity\", IntegerType(), False),\n",
    "        StructField(\"UnitPrice\", FloatType(), False),\n",
    "        StructField(\"TotalPrice\", FloatType(), False),\n",
    "        StructField(\"PaymentMethod\", StringType(), False),\n",
    "        StructField(\"ShippingAddress\", StringType(), False),\n",
    "        StructField(\"LoyaltyPointsEarned\", IntegerType(), False),\n",
    "        StructField(\"GiftWrap\", StringType(), False),\n",
    "        StructField(\"SpecialInstructions\", StringType(), False)\n",
    "    ])\n",
    "\n",
    "    # Create Spark DataFrame and Write to Delta table\n",
    "    transaction_df = spark.createDataFrame(transaction_pdf, schema)\n",
    "    transaction_df.write.mode('overwrite').saveAsTable('bronze_transaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa9256b2-61e4-4e7b-b71c-61374f47be60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate transaction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff451ac-a09e-4e77-944b-c11836a69953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "user_df = spark.read.table(\"bronze_user\")\n",
    "product_df = spark.read.table(\"bronze_product\")\n",
    "transaction_df = spark.read.table(\"bronze_transaction\")\n",
    "\n",
    "# Join the DataFrames\n",
    "joined_df = (\n",
    "    transaction_df\n",
    "    .join(user_df, on=\"UserID\", how=\"left\")\n",
    "    .join(product_df, on=\"ProductID\", how=\"left\")\n",
    ")\n",
    "\n",
    "def inject_issues(df_in, campaign_start_dates):\n",
    "    # Ensure TransactionDate is in the correct format and create 'TempDate'\n",
    "    df = df_in.withColumn('TempDate', F.to_date(F.col('TransactionDate')))\n",
    "    \n",
    "    # Add the Campaign_flag column, initially set to False\n",
    "    df = df.withColumn('Campaign_flag', F.lit(False))\n",
    "    \n",
    "    # Steady nulls around 10-15% in specified columns (e.g., ProductTags, ShippingAddress, Wishlist, GiftWrap)\n",
    "    steady_null_columns = ['ProductTags', 'ShippingAddress', 'Wishlist', 'GiftWrap']\n",
    "    for column in steady_null_columns:\n",
    "        df = df.withColumn(column, F.when(F.rand() < random.uniform(0.1, 0.15), None).otherwise(F.col(column)))\n",
    "    \n",
    "    # Steady nulls around 10% in PreferredPaymentMethod\n",
    "    df = df.withColumn('PreferredPaymentMethod', F.when(F.rand() < random.uniform(0.05, 0.09), None).otherwise(F.col('PreferredPaymentMethod')))\n",
    "    \n",
    "    # 60% zeros in Discount distributed evenly over time\n",
    "    df = df.withColumn('Discount', F.when(F.rand() < 0.6, F.lit(0)).otherwise(F.col('Discount')))\n",
    "    \n",
    "    # 10% zeros in ProductRating distributed evenly over time\n",
    "    df = df.withColumn('ProductRating', F.when(F.rand() < 0.1, F.lit(0)).otherwise(F.col('ProductRating')))\n",
    "    \n",
    "    # Iterate through each campaign start date and apply specific rules\n",
    "    for start_date in campaign_start_dates:\n",
    "        start_date_lit = F.lit(start_date)\n",
    "        campaign_mask = (F.col('TempDate') >= start_date_lit) & (F.col('TempDate') < F.date_add(start_date_lit, 10))\n",
    "        \n",
    "        # Set NumberOfReviews to 0 during the campaign\n",
    "        df = df.withColumn('NumberOfReviews', F.when(campaign_mask, F.lit(0)).otherwise(F.col('NumberOfReviews')))\n",
    "        \n",
    "        # Set PreferredPaymentMethod to null for 48% during the campaign\n",
    "        df = df.withColumn('PreferredPaymentMethod', F.when(campaign_mask & (F.rand() < 0.48), None).otherwise(F.col('PreferredPaymentMethod')))\n",
    "        \n",
    "        # Set PaymentMethod to 'Apple Pay' for 80% during the campaign\n",
    "        df = df.withColumn('PaymentMethod', F.when(campaign_mask & (F.rand() < 0.8), 'Apple Pay').otherwise(F.col('PaymentMethod')))\n",
    "        \n",
    "        # Dramatic change in Quantity and TotalPrice for 10 days after each campaign start date\n",
    "        df = df.withColumn('Quantity', F.when(campaign_mask, F.col('Quantity') * 1.5).otherwise(F.col('Quantity')))\n",
    "        df = df.withColumn('TotalPrice', F.when(campaign_mask, F.col('Quantity') * F.col('UnitPrice')).otherwise(F.col('TotalPrice')))\n",
    "        \n",
    "        # Set the Campaign_flag for these dates and return\n",
    "        return df.withColumn('Campaign_flag', F.when(campaign_mask, F.lit(True)).otherwise(F.col('Campaign_flag')))\n",
    "    \n",
    "    # After 20 days: Apply changes to WarrantyPeriod and ReturnPolicy\n",
    "    last_20_days_mask = (F.col('TempDate').substr(0, 4) == \"2024\") & (F.col('TempDate').substr(6, 2) >= \"05\")\n",
    "    \n",
    "    # Overwrite over 50% of WarrantyPeriod to '15 days'\n",
    "    df = df.withColumn('WarrantyPeriod', F.when(last_20_days_mask & (F.rand() < 0.7), '15 days').otherwise(F.col('WarrantyPeriod')))\n",
    "    \n",
    "    # Overwrite over 50% of ReturnPolicy to 'no returns'\n",
    "    df = df.withColumn('ReturnPolicy', F.when(last_20_days_mask & (F.rand() < 0.7), 'no returns').otherwise(F.col('ReturnPolicy')))\n",
    "    \n",
    "    # Drop the temporary date column\n",
    "    df = df.drop('TempDate')\n",
    "    \n",
    "    return df\n",
    "\n",
    "if not data_exists:\n",
    "    # Define current date\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Generate campaign start dates as a list\n",
    "    campaign_start_dates = [(current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "    # Alternatively, you can use predefined campaign dates (uncomment if needed)\n",
    "    # campaign_start_dates = [\"2023-07-15\", \"2023-11-23\", \"2024-03-10\", (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "    # Apply the inject_issues_spark function to the Spark DataFrame\n",
    "    joined_with_issues_df = inject_issues(joined_df, campaign_start_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575aa450-7642-4279-ab6e-9995013393ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    # Define the schema\n",
    "    schema = StructType([\n",
    "        StructField('TransactionID', StringType(), True),\n",
    "        StructField('UserID', StringType(), True),\n",
    "        StructField('ProductID', StringType(), True),\n",
    "        StructField('TransactionDate', TimestampType(), True),\n",
    "        StructField('Quantity', DoubleType(), True),\n",
    "        StructField('UnitPrice', DoubleType(), True),\n",
    "        StructField('TotalPrice', DoubleType(), True),\n",
    "        StructField('PaymentMethod', StringType(), True),\n",
    "        StructField('ShippingAddress', StringType(), True),\n",
    "        StructField('LoyaltyPointsEarned', IntegerType(), True),\n",
    "        StructField('GiftWrap', StringType(), True),\n",
    "        StructField('SpecialInstructions', StringType(), True),\n",
    "        StructField('Username', StringType(), True),\n",
    "        StructField('Email', StringType(), True),\n",
    "        StructField('PasswordHash', StringType(), True),\n",
    "        StructField('FullName', StringType(), True),\n",
    "        StructField('DateOfBirth', DateType(), True),\n",
    "        StructField('Gender', StringType(), True),\n",
    "        StructField('PhoneNumber', StringType(), True),\n",
    "        StructField('Address', StringType(), True),\n",
    "        StructField('City', StringType(), True),\n",
    "        StructField('State', StringType(), True),\n",
    "        StructField('Country', StringType(), True),\n",
    "        StructField('PostalCode', StringType(), True),\n",
    "        StructField('RegistrationDate', DateType(), True),\n",
    "        StructField('LastLoginDate', TimestampType(), True),\n",
    "        StructField('AccountStatus', StringType(), True),\n",
    "        StructField('UserRole', StringType(), True),\n",
    "        StructField('PreferredPaymentMethod', StringType(), True),\n",
    "        StructField('TotalPurchaseAmount', DoubleType(), True),\n",
    "        StructField('NewsletterSubscription', BooleanType(), True),\n",
    "        StructField('Wishlist', ArrayType(StringType()), True),\n",
    "        StructField('CartItems', ArrayType(StringType()), True),\n",
    "        StructField('ProductName', StringType(), True),\n",
    "        StructField('Category', StringType(), True),\n",
    "        StructField('SubCategory', StringType(), True),\n",
    "        StructField('Brand', StringType(), True),\n",
    "        StructField('Description', StringType(), True),\n",
    "        StructField('Price', DoubleType(), True),\n",
    "        StructField('Discount', DoubleType(), True),\n",
    "        StructField('StockQuantity', IntegerType(), True),\n",
    "        StructField('SKU', StringType(), True),\n",
    "        StructField('ProductImageURL', StringType(), True),\n",
    "        StructField('ProductRating', DoubleType(), True),\n",
    "        StructField('NumberOfReviews', IntegerType(), True),\n",
    "        StructField('SupplierID', StringType(), True),\n",
    "        StructField('DateAdded', DateType(), True),\n",
    "        StructField('Dimensions', StringType(), True),\n",
    "        StructField('Weight', DoubleType(), True),\n",
    "        StructField('Color', StringType(), True),\n",
    "        StructField('Material', StringType(), True),\n",
    "        StructField('WarrantyPeriod', StringType(), True),\n",
    "        StructField('ReturnPolicy', StringType(), True),\n",
    "        StructField('ShippingCost', DoubleType(), True),\n",
    "        StructField('ProductTags', ArrayType(StringType()), True),\n",
    "        StructField('Campaign_flag', BooleanType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Make sure to convert dates like 'DateOfBirth', 'RegistrationDate', and 'DateAdded' to appropriate formats\n",
    "    joined_with_issues_df = joined_with_issues_df \\\n",
    "        .withColumn('DateOfBirth', F.col('DateOfBirth').cast(DateType())) \\\n",
    "        .withColumn('RegistrationDate', F.col('RegistrationDate').cast(DateType())) \\\n",
    "        .withColumn('DateAdded', F.col('DateAdded').cast(DateType()))\n",
    "\n",
    "    # Ensure Wishlist, CartItems, and ProductTags are either arrays or null and Write to Delta as \"Silver transaction\" table\n",
    "    joined_with_issues_df = joined_with_issues_df \\\n",
    "        .withColumn('Wishlist', F.when(F.col('Wishlist').isNull(), None).otherwise(F.col('Wishlist'))) \\\n",
    "        .withColumn('CartItems', F.when(F.col('CartItems').isNull(), None).otherwise(F.col('CartItems'))) \\\n",
    "        .withColumn('ProductTags', F.when(F.col('ProductTags').isNull(), None).otherwise(F.col('ProductTags')))\n",
    "        \n",
    "    joined_with_issues_df.write.option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable('silver_transaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dda6ed19-9b5f-4b1d-b5f8-507b6c2a8713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Gold table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdef5e44-cded-4719-ad43-92c0e6130c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    from pyspark.sql import Window\n",
    "\n",
    "    # Create a temporary column for Month from silver table\n",
    "    tmp_df = spark.read.table(\"silver_transaction\").withColumn(\"Month\", F.date_format(F.col(\"TransactionDate\"), \"yyyy-MM\"))\n",
    "\n",
    "    ## Monthly Sales Summary by Category\n",
    "    tmp_df \\\n",
    "        .groupBy(\"Month\", \"Category\") \\\n",
    "        .agg(\n",
    "            F.sum(\"TotalPrice\").alias(\"TotalSales\"),\n",
    "            F.sum(\"Quantity\").alias(\"TotalQuantitySold\")\n",
    "        ) \\\n",
    "        .orderBy(\"Month\", \"Category\") \\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable(f'gold_monthly_sales')\n",
    "\n",
    "    ## Top 10 Products by Total Sales by Month\n",
    "    tmp_df \\\n",
    "        .groupBy(\"Month\", \"ProductID\", \"ProductName\") \\\n",
    "        .agg(\n",
    "            F.sum(\"TotalPrice\").alias(\"TotalSales\")\n",
    "        ) \\\n",
    "        .withColumn(\"Rank\", F.row_number().over(Window.partitionBy(\"Month\").orderBy(F.desc(\"TotalSales\")))) \\\n",
    "        .filter(F.col(\"Rank\") <= 10) \\\n",
    "        .orderBy(\"Month\", \"Rank\")\\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable('gold_top_products')\n",
    "\n",
    "    ## User Purchase Behavior by Month\n",
    "    tmp_df \\\n",
    "        .groupBy(\"Month\", \"UserID\", \"Username\") \\\n",
    "        .agg(\n",
    "            F.sum(\"TotalPrice\").alias(\"TotalPurchaseAmount\"),\n",
    "            F.avg(\"TotalPrice\").alias(\"AveragePurchaseAmount\"),\n",
    "            F.count(\"TransactionID\").alias(\"TotalTransactions\")\n",
    "        ) \\\n",
    "        .orderBy(\"Month\", \"UserID\") \\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable('gold_user_purchase')\n",
    "\n",
    "    ## Gold Payment methods\n",
    "    spark.read.table(\"silver_transaction\") \\\n",
    "        .select(\n",
    "            \"TransactionID\", \n",
    "            \"UserID\", \n",
    "            \"PaymentMethod\", \n",
    "            \"PreferredPaymentMethod\", \n",
    "            \"Price\", \n",
    "            \"Quantity\"\n",
    "        ) \\\n",
    "        .orderBy(\"TransactionID\") \\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable('gold_payment_method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89887ffc-024f-469e-b5cb-515ee00d5d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Delete tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "090a7fb9-c12e-4df9-8328-ae7f47b36743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE IF EXISTS gold_payment_method\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS silver_transaction\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS bronze_transaction\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS bronze_product\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS bronze_user\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS bronze_product\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-DataGeneration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
